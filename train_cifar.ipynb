{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from torchvision import transforms\n",
    "import my_dataset\n",
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from vit_pytorch import ViT\n",
    "from vit_pytorch.t2t import T2TViT\n",
    "from vit_pytorch.cct import CCT\n",
    "from linformer import Linformer\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 60\n",
    "lr = 2e-5\n",
    "gamma = 0.7\n",
    "batch_size = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = utils.read_file(\"../cifar10/train_data.txt\")\n",
    "val_data = utils.read_file(\"../cifar10/val_data.txt\")\n",
    "test_data = utils.read_file(\"../cifar10/test_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = {\n",
    "        \"train\": transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])]),\n",
    "        \"val\": transforms.Compose([transforms.ToTensor(),\n",
    "                                   transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = my_dataset.MyDataSet_CIFAR(images_path=train_data,\n",
    "                        transform=data_transform[\"train\"])\n",
    "\n",
    "val_dataset = my_dataset.MyDataSet_CIFAR(images_path=val_data,\n",
    "                        transform=data_transform[\"val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 8 dataloader workers every process\n"
     ]
    }
   ],
   "source": [
    "nw = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 8])  # number of workers\n",
    "print('Using {} dataloader workers every process'.format(nw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                            batch_size = batch_size,\n",
    "                                            shuffle=True,\n",
    "                                            pin_memory=True,\n",
    "                                            num_workers=nw,\n",
    "                                            collate_fn=train_dataset.collate_fn)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                            batch_size = batch_size,\n",
    "                                            shuffle=True,\n",
    "                                            pin_memory=True,\n",
    "                                            num_workers=nw,\n",
    "                                            collate_fn=val_dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ViT(\n",
    "#     image_size = 256,\n",
    "#     patch_size = 32,\n",
    "#     num_classes = 20,\n",
    "#     dim = 1024,\n",
    "#     depth = 6,\n",
    "#     heads = 16,\n",
    "#     mlp_dim = 2048,\n",
    "#     dropout = 0.1,\n",
    "#     emb_dropout = 0.1\n",
    "# ).to(device)\n",
    "\n",
    "# model = T2TViT(\n",
    "#     dim = 512,\n",
    "#     image_size = 32,\n",
    "#     depth = 10,\n",
    "#     heads = 12,\n",
    "#     mlp_dim = 512,\n",
    "#     num_classes = 10,\n",
    "#     t2t_layers = ((7, 4), (3, 2), (3, 2)) # tuples of the kernel size and stride of each consecutive layers of the initial token to token module\n",
    "# ).to(device)\n",
    "\n",
    "model = CCT(\n",
    "    img_size = 32,\n",
    "    embedding_dim = 384,\n",
    "    n_conv_layers = 2,\n",
    "    kernel_size = 7,\n",
    "    stride = 2,\n",
    "    padding = 3,\n",
    "    pooling_kernel_size = 3,\n",
    "    pooling_stride = 2,\n",
    "    pooling_padding = 1,\n",
    "    num_layers = 14,\n",
    "    num_heads = 6,\n",
    "    mlp_radio = 3.,\n",
    "    num_classes = 10,\n",
    "    positional_embedding = 'learnable', # ['sine', 'learnable', 'none']\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "# scheduler\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[train epoch 0] loss: 1.583, acc: 0.428: 100%|██████████| 547/547 [00:27<00:00, 19.78it/s]\n",
      "[valid epoch 0] loss: 1.377, acc: 0.505: 100%|██████████| 157/157 [00:01<00:00, 89.70it/s] \n",
      "[train epoch 1] loss: 1.298, acc: 0.538: 100%|██████████| 547/547 [00:24<00:00, 22.39it/s]\n",
      "[valid epoch 1] loss: 1.263, acc: 0.547: 100%|██████████| 157/157 [00:01<00:00, 92.11it/s] \n",
      "[train epoch 2] loss: 1.201, acc: 0.574: 100%|██████████| 547/547 [00:24<00:00, 22.43it/s]\n",
      "[valid epoch 2] loss: 1.205, acc: 0.566: 100%|██████████| 157/157 [00:01<00:00, 91.29it/s] \n",
      "[train epoch 3] loss: 1.133, acc: 0.599: 100%|██████████| 547/547 [00:24<00:00, 22.55it/s]\n",
      "[valid epoch 3] loss: 1.184, acc: 0.579: 100%|██████████| 157/157 [00:01<00:00, 91.65it/s] \n",
      "[train epoch 4] loss: 1.092, acc: 0.616: 100%|██████████| 547/547 [00:24<00:00, 22.43it/s]\n",
      "[valid epoch 4] loss: 1.164, acc: 0.587: 100%|██████████| 157/157 [00:01<00:00, 90.64it/s] \n",
      "[train epoch 5] loss: 1.061, acc: 0.627: 100%|██████████| 547/547 [00:24<00:00, 22.35it/s]\n",
      "[valid epoch 5] loss: 1.149, acc: 0.593: 100%|██████████| 157/157 [00:01<00:00, 90.90it/s] \n",
      "[train epoch 6] loss: 1.041, acc: 0.635: 100%|██████████| 547/547 [00:24<00:00, 22.20it/s]\n",
      "[valid epoch 6] loss: 1.137, acc: 0.598: 100%|██████████| 157/157 [00:01<00:00, 91.97it/s] \n",
      "[train epoch 7] loss: 1.025, acc: 0.639: 100%|██████████| 547/547 [00:24<00:00, 22.40it/s]\n",
      "[valid epoch 7] loss: 1.142, acc: 0.596: 100%|██████████| 157/157 [00:01<00:00, 89.88it/s] \n",
      "[train epoch 8] loss: 1.014, acc: 0.644: 100%|██████████| 547/547 [00:24<00:00, 22.22it/s]\n",
      "[valid epoch 8] loss: 1.133, acc: 0.598: 100%|██████████| 157/157 [00:01<00:00, 90.12it/s] \n",
      "[train epoch 9] loss: 1.007, acc: 0.646: 100%|██████████| 547/547 [00:24<00:00, 22.26it/s]\n",
      "[valid epoch 9] loss: 1.130, acc: 0.598: 100%|██████████| 157/157 [00:01<00:00, 90.70it/s] \n",
      "[train epoch 10] loss: 0.999, acc: 0.649: 100%|██████████| 547/547 [00:24<00:00, 22.33it/s]\n",
      "[valid epoch 10] loss: 1.129, acc: 0.600: 100%|██████████| 157/157 [00:01<00:00, 90.77it/s] \n",
      "[train epoch 11] loss: 0.997, acc: 0.650: 100%|██████████| 547/547 [00:24<00:00, 22.64it/s]\n",
      "[valid epoch 11] loss: 1.128, acc: 0.601: 100%|██████████| 157/157 [00:01<00:00, 101.35it/s]\n",
      "[train epoch 12] loss: 0.993, acc: 0.653: 100%|██████████| 547/547 [00:22<00:00, 24.01it/s]\n",
      "[valid epoch 12] loss: 1.126, acc: 0.602: 100%|██████████| 157/157 [00:01<00:00, 103.23it/s]\n",
      "[train epoch 13] loss: 0.993, acc: 0.653: 100%|██████████| 547/547 [00:22<00:00, 23.81it/s]\n",
      "[valid epoch 13] loss: 1.127, acc: 0.602: 100%|██████████| 157/157 [00:01<00:00, 101.74it/s]\n",
      "[train epoch 14] loss: 0.992, acc: 0.655: 100%|██████████| 547/547 [00:22<00:00, 23.79it/s]\n",
      "[valid epoch 14] loss: 1.127, acc: 0.603: 100%|██████████| 157/157 [00:01<00:00, 106.11it/s]\n",
      "[train epoch 15] loss: 0.988, acc: 0.653: 100%|██████████| 547/547 [00:22<00:00, 24.02it/s]\n",
      "[valid epoch 15] loss: 1.124, acc: 0.603: 100%|██████████| 157/157 [00:01<00:00, 106.83it/s]\n",
      "[train epoch 16] loss: 0.992, acc: 0.652: 100%|██████████| 547/547 [00:22<00:00, 24.07it/s]\n",
      "[valid epoch 16] loss: 1.126, acc: 0.603: 100%|██████████| 157/157 [00:01<00:00, 106.19it/s]\n",
      "[train epoch 17] loss: 0.991, acc: 0.651: 100%|██████████| 547/547 [00:23<00:00, 23.67it/s]\n",
      "[valid epoch 17] loss: 1.124, acc: 0.603: 100%|██████████| 157/157 [00:01<00:00, 93.35it/s] \n",
      "[train epoch 18] loss: 0.990, acc: 0.653: 100%|██████████| 547/547 [00:24<00:00, 22.55it/s]\n",
      "[valid epoch 18] loss: 1.125, acc: 0.603: 100%|██████████| 157/157 [00:01<00:00, 98.90it/s] \n",
      "[train epoch 19] loss: 0.992, acc: 0.652: 100%|██████████| 547/547 [00:22<00:00, 23.93it/s]\n",
      "[valid epoch 19] loss: 1.125, acc: 0.603: 100%|██████████| 157/157 [00:01<00:00, 104.80it/s]\n",
      "[train epoch 20] loss: 0.989, acc: 0.652: 100%|██████████| 547/547 [00:22<00:00, 24.01it/s]\n",
      "[valid epoch 20] loss: 1.129, acc: 0.603: 100%|██████████| 157/157 [00:01<00:00, 105.02it/s]\n",
      "[train epoch 21] loss: 0.989, acc: 0.652: 100%|██████████| 547/547 [00:22<00:00, 24.03it/s]\n",
      "[valid epoch 21] loss: 1.126, acc: 0.603: 100%|██████████| 157/157 [00:01<00:00, 106.82it/s]\n",
      "[train epoch 22] loss: 0.989, acc: 0.653: 100%|██████████| 547/547 [00:23<00:00, 23.61it/s]\n",
      "[valid epoch 22] loss: 1.126, acc: 0.603: 100%|██████████| 157/157 [00:01<00:00, 99.70it/s] \n",
      "[train epoch 23] loss: 0.988, acc: 0.654: 100%|██████████| 547/547 [00:22<00:00, 23.91it/s]\n",
      "[valid epoch 23] loss: 1.125, acc: 0.603: 100%|██████████| 157/157 [00:01<00:00, 102.74it/s]\n",
      "[train epoch 24] loss: 0.986, acc: 0.655: 100%|██████████| 547/547 [00:22<00:00, 23.82it/s]\n",
      "[valid epoch 24] loss: 1.124, acc: 0.603: 100%|██████████| 157/157 [00:01<00:00, 105.70it/s]\n",
      "[train epoch 25] loss: 0.985, acc: 0.657: 100%|██████████| 547/547 [00:22<00:00, 23.87it/s]\n",
      "[valid epoch 25] loss: 1.126, acc: 0.603: 100%|██████████| 157/157 [00:01<00:00, 98.54it/s] \n",
      "[train epoch 26] loss: 0.989, acc: 0.656: 100%|██████████| 547/547 [00:22<00:00, 23.79it/s]\n",
      "[valid epoch 26] loss: 1.124, acc: 0.603: 100%|██████████| 157/157 [00:01<00:00, 107.76it/s]\n",
      "[train epoch 27] loss: 0.987, acc: 0.655: 100%|██████████| 547/547 [00:22<00:00, 24.00it/s]\n",
      "[valid epoch 27] loss: 1.125, acc: 0.603: 100%|██████████| 157/157 [00:01<00:00, 107.73it/s]\n",
      "[train epoch 28] loss: 0.987, acc: 0.654: 100%|██████████| 547/547 [00:23<00:00, 23.57it/s]\n",
      "[valid epoch 28] loss: 1.124, acc: 0.603: 100%|██████████| 157/157 [00:01<00:00, 109.44it/s]\n",
      "[train epoch 29] loss: 0.992, acc: 0.652: 100%|██████████| 547/547 [00:23<00:00, 23.71it/s]\n",
      "[valid epoch 29] loss: 1.127, acc: 0.603: 100%|██████████| 157/157 [00:01<00:00, 98.93it/s] \n",
      "[train epoch 30] loss: 0.988, acc: 0.655: 100%|██████████| 547/547 [00:23<00:00, 23.78it/s]\n",
      "[valid epoch 30] loss: 1.124, acc: 0.603: 100%|██████████| 157/157 [00:01<00:00, 106.15it/s]\n",
      "[train epoch 31] loss: 0.987, acc: 0.653: 100%|██████████| 547/547 [00:22<00:00, 24.10it/s]\n",
      "[valid epoch 31] loss: 1.126, acc: 0.603: 100%|██████████| 157/157 [00:01<00:00, 106.27it/s]\n",
      "[train epoch 32] loss: 0.990, acc: 0.653: 100%|██████████| 547/547 [00:22<00:00, 24.07it/s]\n",
      "[valid epoch 32] loss: 1.124, acc: 0.603: 100%|██████████| 157/157 [00:01<00:00, 105.51it/s]\n",
      "[train epoch 33] loss: 0.984, acc: 0.656: 100%|██████████| 547/547 [00:22<00:00, 24.04it/s]\n",
      "[valid epoch 33] loss: 1.126, acc: 0.603: 100%|██████████| 157/157 [00:01<00:00, 104.93it/s]\n",
      "[train epoch 34] loss: 0.993, acc: 0.653: 100%|██████████| 547/547 [00:23<00:00, 23.68it/s]\n",
      "[valid epoch 34] loss: 1.128, acc: 0.603: 100%|██████████| 157/157 [00:01<00:00, 107.74it/s]\n",
      "[train epoch 35] loss: 0.989, acc: 0.654: 100%|██████████| 547/547 [00:22<00:00, 23.90it/s]\n",
      "[valid epoch 35] loss: 1.124, acc: 0.603: 100%|██████████| 157/157 [00:01<00:00, 105.47it/s]\n",
      "[train epoch 36] loss: 0.987, acc: 0.656: 100%|██████████| 547/547 [00:22<00:00, 24.00it/s]\n",
      "[valid epoch 36] loss: 1.126, acc: 0.603: 100%|██████████| 157/157 [00:01<00:00, 107.33it/s]\n",
      "[train epoch 37] loss: 0.991, acc: 0.653: 100%|██████████| 547/547 [00:22<00:00, 23.84it/s]\n",
      "[valid epoch 37] loss: 1.124, acc: 0.603: 100%|██████████| 157/157 [00:01<00:00, 99.91it/s] \n",
      "[train epoch 38] loss: 0.987, acc: 0.655: 100%|██████████| 547/547 [00:22<00:00, 24.03it/s]\n",
      "[valid epoch 38] loss: 1.124, acc: 0.603: 100%|██████████| 157/157 [00:01<00:00, 102.66it/s]\n",
      "[train epoch 39] loss: 0.987, acc: 0.655: 100%|██████████| 547/547 [00:22<00:00, 23.87it/s]\n",
      "[valid epoch 39] loss: 1.124, acc: 0.603: 100%|██████████| 157/157 [00:01<00:00, 103.23it/s]\n",
      "[train epoch 40] loss: 0.987, acc: 0.656: 100%|██████████| 547/547 [00:22<00:00, 23.79it/s]\n",
      "[valid epoch 40] loss: 1.125, acc: 0.603: 100%|██████████| 157/157 [00:01<00:00, 102.62it/s]\n",
      "[train epoch 41] loss: 0.990, acc: 0.653: 100%|██████████| 547/547 [00:23<00:00, 23.74it/s]\n",
      "[valid epoch 41] loss: 1.125, acc: 0.603: 100%|██████████| 157/157 [00:01<00:00, 99.92it/s] \n",
      "[train epoch 42] loss: 0.989, acc: 0.653: 100%|██████████| 547/547 [00:23<00:00, 23.64it/s]\n",
      "[valid epoch 42] loss: 1.125, acc: 0.603: 100%|██████████| 157/157 [00:01<00:00, 106.85it/s]\n",
      "[train epoch 43] loss: 0.990, acc: 0.654: 100%|██████████| 547/547 [00:22<00:00, 23.88it/s]\n",
      "[valid epoch 43] loss: 1.124, acc: 0.603: 100%|██████████| 157/157 [00:01<00:00, 101.09it/s]\n",
      "[train epoch 44] loss: 0.990, acc: 0.654: 100%|██████████| 547/547 [00:23<00:00, 23.70it/s]\n",
      "[valid epoch 44] loss: 1.128, acc: 0.603: 100%|██████████| 157/157 [00:01<00:00, 95.19it/s] \n",
      "[train epoch 45] loss: 0.989, acc: 0.654: 100%|██████████| 547/547 [00:25<00:00, 21.40it/s]\n",
      "[valid epoch 45] loss: 1.125, acc: 0.603: 100%|██████████| 157/157 [00:02<00:00, 72.54it/s] \n",
      "[train epoch 46] loss: 0.989, acc: 0.654: 100%|██████████| 547/547 [00:24<00:00, 21.95it/s]\n",
      "[valid epoch 46] loss: 1.126, acc: 0.603: 100%|██████████| 157/157 [00:01<00:00, 94.22it/s] \n",
      "[train epoch 47] loss: 0.986, acc: 0.655: 100%|██████████| 547/547 [00:24<00:00, 22.45it/s]\n",
      "[valid epoch 47] loss: 1.125, acc: 0.603: 100%|██████████| 157/157 [00:01<00:00, 92.60it/s] \n",
      "[train epoch 48] loss: 0.987, acc: 0.655: 100%|██████████| 547/547 [00:25<00:00, 21.81it/s]\n",
      "[valid epoch 48] loss: 1.125, acc: 0.603: 100%|██████████| 157/157 [00:01<00:00, 85.26it/s]\n",
      "[train epoch 49] loss: 0.991, acc: 0.656: 100%|██████████| 547/547 [00:24<00:00, 22.16it/s]\n",
      "[valid epoch 49] loss: 1.124, acc: 0.603: 100%|██████████| 157/157 [00:01<00:00, 95.10it/s] \n",
      "[train epoch 50] loss: 0.988, acc: 0.653: 100%|██████████| 547/547 [00:25<00:00, 21.59it/s]\n",
      "[valid epoch 50] loss: 1.128, acc: 0.603: 100%|██████████| 157/157 [00:01<00:00, 95.82it/s] \n",
      "[train epoch 51] loss: 0.987, acc: 0.657: 100%|██████████| 547/547 [00:25<00:00, 21.47it/s]\n",
      "[valid epoch 51] loss: 1.125, acc: 0.603: 100%|██████████| 157/157 [00:01<00:00, 88.77it/s] \n",
      "[train epoch 52] loss: 0.988, acc: 0.653: 100%|██████████| 547/547 [00:24<00:00, 21.93it/s]\n",
      "[valid epoch 52] loss: 1.125, acc: 0.603: 100%|██████████| 157/157 [00:01<00:00, 92.32it/s] \n",
      "[train epoch 53] loss: 0.988, acc: 0.653: 100%|██████████| 547/547 [00:24<00:00, 22.29it/s]\n",
      "[valid epoch 53] loss: 1.125, acc: 0.603: 100%|██████████| 157/157 [00:01<00:00, 91.07it/s] \n",
      "[train epoch 54] loss: 0.986, acc: 0.655: 100%|██████████| 547/547 [00:24<00:00, 22.42it/s]\n",
      "[valid epoch 54] loss: 1.125, acc: 0.603: 100%|██████████| 157/157 [00:01<00:00, 90.98it/s] \n",
      "[train epoch 55] loss: 0.989, acc: 0.652: 100%|██████████| 547/547 [00:24<00:00, 22.28it/s]\n",
      "[valid epoch 55] loss: 1.124, acc: 0.603: 100%|██████████| 157/157 [00:01<00:00, 92.46it/s] \n",
      "[train epoch 56] loss: 0.993, acc: 0.653: 100%|██████████| 547/547 [00:24<00:00, 22.34it/s]\n",
      "[valid epoch 56] loss: 1.125, acc: 0.603: 100%|██████████| 157/157 [00:01<00:00, 91.62it/s] \n",
      "[train epoch 57] loss: 0.987, acc: 0.654: 100%|██████████| 547/547 [00:24<00:00, 22.29it/s]\n",
      "[valid epoch 57] loss: 1.126, acc: 0.603: 100%|██████████| 157/157 [00:01<00:00, 90.93it/s] \n",
      "[train epoch 58] loss: 0.986, acc: 0.655: 100%|██████████| 547/547 [00:24<00:00, 22.40it/s]\n",
      "[valid epoch 58] loss: 1.125, acc: 0.603: 100%|██████████| 157/157 [00:01<00:00, 90.00it/s] \n",
      "[train epoch 59] loss: 0.987, acc: 0.656: 100%|██████████| 547/547 [00:24<00:00, 22.35it/s]\n",
      "[valid epoch 59] loss: 1.126, acc: 0.603: 100%|██████████| 157/157 [00:01<00:00, 93.70it/s] \n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    \n",
    "    model.train()\n",
    "    accu_loss = torch.zeros(1).to(device)  # 累计损失\n",
    "    accu_num = torch.zeros(1).to(device)  # 累计预测正确的样本数\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    sample_num = 0\n",
    "    data_loader = tqdm(train_loader)\n",
    "    for step, data in enumerate(data_loader):\n",
    "        images, labels = data\n",
    "\n",
    "        sample_num += images.shape[0]\n",
    "\n",
    "        pred = model(images.to(device))\n",
    "        \n",
    "        pred_classes = torch.max(pred, dim=1)[1]  # 预测的类别，[1]是标签索引\n",
    "       \n",
    "        \n",
    "        accu_num += torch.eq(pred_classes, labels.to(device)).sum()\n",
    "        loss = loss_function(pred, labels.to(device))\n",
    "        loss.backward()\n",
    "        \n",
    "        accu_loss += loss.detach()\n",
    "        \n",
    "        data_loader.desc = \"[train epoch {}] loss: {:.3f}, acc: {:.3f}\".format(epoch,\n",
    "                                                                               accu_loss.item() / (step + 1),\n",
    "                                                                               accu_num.item() / sample_num)\n",
    "        optimizer.step()  # 更新\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    train_loss =  accu_loss.item() / (step + 1)\n",
    "    train_acc = accu_num.item() / sample_num\n",
    "    scheduler.step()\n",
    "    val_loss, val_acc = utils.evaluate(model=model,\n",
    "                                data_loader=val_loader,\n",
    "                                device=device,\n",
    "                                epoch=epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('env1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac2c9fc71220d1b58b3640599b1e22027da1326aa67720425adf09ad6c638495"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
