{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from torchvision import transforms\n",
    "import my_dataset\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path_train = utils.read_file(\"./data/train-path.txt\")\n",
    "image_path_val = utils.read_file(\"./data/val-path.txt\")\n",
    "image_path_test = utils.read_file(\"./data/test-path.txt\")\n",
    "labels_train = utils.read_file(\"./data/train-anno.txt\",\"int\")\n",
    "labels_val = utils.read_file(\"./data/val-anno.txt\",\"int\")\n",
    "labels_test = utils.read_file(\"./data/test-anno.txt\",\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = {\n",
    "        \"train\": transforms.Compose([transforms.RandomResizedCrop(256),\n",
    "                                     transforms.RandomHorizontalFlip(),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])]),\n",
    "        \"val\": transforms.Compose([transforms.Resize(256),\n",
    "                                   transforms.CenterCrop(224),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = my_dataset.MyDataSet(images_path=image_path_train,\n",
    "                        images_class=labels_train,\n",
    "                        transform=data_transform[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "nw = min([os.cpu_count(), BATCH_SIZE if BATCH_SIZE > 1 else 0, 8])  # number of workers\n",
    "print('Using {} dataloader workers every process'.format(nw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                            batch_size=BATCH_SIZE,\n",
    "                                            shuffle=True,\n",
    "                                            pin_memory=True,\n",
    "                                            num_workers=nw,\n",
    "                                            collate_fn=train_dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1498/1498 [00:31<00:00, 47.88it/s]\n"
     ]
    }
   ],
   "source": [
    "data_loader = tqdm(train_loader)\n",
    "for step, data in enumerate(data_loader):\n",
    "        images, labels = data\n",
    "        # print(\"The shape of images : \", images.shape)\n",
    "        # print(\"The shape of labels : \", labels.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('env1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac2c9fc71220d1b58b3640599b1e22027da1326aa67720425adf09ad6c638495"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
